fix(agree)
fix(r)
fix(r)
agree<-reduce(intersect, list(r,s))
vowel.test1<-vowel.test[agree,]
error3<-1-sum(s[agree]==vowel.test1$y)/length(vowel.test1$y)
agree<-intersect(activity,activity1)
vowel.test1<-vowel.test[agree,]
error3<-1-sum(s[agree]==vowel.test1$y)/length(vowel.test1$y)
error3
install.packages("twitterR")
install.packages("twitterR")
install.packages("C:/Users/IBM_ADMIN/Desktop/twitteR_1.1.0.zip", repos = NULL)
searchTwitter(corrupcion)
library("twitteR", lib.loc="C:/Users/IBM_ADMIN/Documents/R/win-library/2.15")
searchTwitter(corrupcion)
searchTwitter("#corrupcion",n=100)
install.packages("FacebookR")
searchTwitter("#corrupcion",n=100)
searchTwitter("#corrupcion",n=100)
searchTwitter("#corrupcion",n=100)
searchTwitter("#corrupcion",n=100)
detach("package:twitteR", unload=TRUE)
library("twitteR", lib.loc="C:/Users/IBM_ADMIN/Documents/R/win-library/2.15")
searchTwitter("#corrupcion",n=100)
detach("package:twitteR", unload=TRUE)
library("twitteR", lib.loc="C:/Users/IBM_ADMIN/Documents/R/win-library/2.15")
searchTwitter("#corrupcion",n=100)
cred <- OAuthFactory$new(consumerKey=Z5TKsM1A5xhyQizfr4FB0g,
+ consumerSecret=IZjB4A6iuHPae5ARs51a9COX9s9Jol3E1jMH3Yhw1s,
+ requestURL=https://api.twitter.com/oauth/request_token,
+ accessURL=https://api.twitter.com/oauth/authorize,
+ authURL=https://api.twitter.com/oauth/access_token)
cred <- OAuthFactory$new(consumerKey=Z5TKsM1A5xhyQizfr4FB0g,
+ consumerSecret=IZjB4A6iuHPae5ARs51a9COX9s9Jol3E1jMH3Yhw1s,
+ requestURL="https://api.twitter.com/oauth/request_token",
+ accessURL="https://api.twitter.com/oauth/authorize",
+ authURL="https://api.twitter.com/oauth/access_token")
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "Z5TKsM1A5xhyQizfr4FB0g"
consumerSecret <- "IZjB4A6iuHPae5ARs51a9COX9s9Jol3E1jMH3Yhw1s"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
twitCred$handshake()
registerTwitterOAuth(twitCred)
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
+ consumerSecret=consumerSecret,
+ requestURL=reqURL,
+ accessURL=accessURL,
+ authURL=authURL)
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
twitCred <- OAuth$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
twitCred <- Factory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
install.packages("twitteR")
library("twitteR", lib.loc="C:/Users/IBM_ADMIN/Documents/R/win-library/2.15")
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=reqURL,
accessURL=accessURL,
authURL=authURL)
install.packages("twitteR")
library("twitteR", lib.loc="C:/Users/IBM_ADMIN/Documents/R/win-library/2.15")
requestURL<-"https://api.twitter.com/oauth/request_token"
accessURL<-"https://api.twitter.com/oauth/access_token"
authURL<-"https://api.twitter.com/oauth/authorize"
consumerKey<-"Z5TKsM1A5xhyQizfr4FB0g"
consumerSecret<-"IZjB4A6iuHPae5ARs51a9COX9s9Jol3E1jMH3Yhw1s"
cred <- OAuthFactory$new(consumerKey=YOURKEY,
+ consumerSecret=YOURSECRET,
+ requestURL=requestURL,
+ accessURL=accessURL,
+ authURL=authURL)
cred <- OAuthFactory$new(consumerKey=YOURKEY,
consumerSecret=YOURSECRET,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
cred <- OAuthFactory$new(consumerKey=YOURKEY,
consumerSecret=YOURSECRET,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
install.packages("maptools")
install.packages("bigr")
install.packages("bigRR")
# Load required library
library(recommenderlab) # package being evaluated
install.packages("recommenderLab")
install.packages("recommenderlab")
library(recommenderlab) # package being evaluated
library(ggplot2) # For plots
# Load the data we are going to work with
data(MovieLense)
MovieLense
# 943 x 1664 rating matrix of class ‘realRatingMatrix’ with 99392 ratings.
# Visualizing a sample of this
image(sample(MovieLense, 500), main = "Raw ratings")
# Visualizing ratings
qplot(getRatings(MovieLense), binwidth = 1,
main = "Histogram of ratings", xlab = "Rating")
summary(getRatings(MovieLense)) # Skewed to the right
# How about after normalization?
qplot(getRatings(normalize(MovieLense, method = "Z-score")),
main = "Histogram of normalized ratings", xlab = "Rating")
summary(getRatings(normalize(MovieLense, method = "Z-score")))
# How many movies did people rate on average
qplot(rowCounts(MovieLense), binwidth = 10,
main = "Movies Rated on average",
xlab = "# of users",
ylab = "# of movies rated")
# What is the mean rating of each movie
qplot(colMeans(MovieLense), binwidth = .1,
main = "Mean rating of Movies",
xlab = "Rating",
ylab = "# of movies")
# The big spike on 1 suggests that this could also be intepreted as binary
# In other words, some people don't want to see certain movies at all.
# Same on 5 and on 3.
# We will give it the binary treatment later
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
# We have a few options
# Let's check some algorithms against each other
scheme <- evaluationScheme(MovieLense, method = "split", train = .9,
k = 1, given = 10, goodRating = 4)
scheme
algorithms <- list(
"random items" = list(name="RANDOM", param=list(normalize = "Z-score")),
"popular items" = list(name="POPULAR", param=list(normalize = "Z-score")),
"user-based CF" = list(name="UBCF", param=list(normalize = "Z-score",
method="Cosine",
nn=50, minRating=3)),
"item-based CF" = list(name="IBCF2", param=list(normalize = "Z-score"
))
)
# run algorithms, predict next n movies
results <- evaluate(scheme, algorithms, n=c(1, 3, 5, 10, 15, 20))
# Draw ROC curve
plot(results, annotate = 1:4, legend="topleft")
# See precision / recall
plot(results, "prec/rec", annotate=3)
data(titanic)
data(titanic.raw)
str(titanic.raw)
data<-load("C:/Users/IBM_ADMIN/Desktop/Learning/titanic.raw.RData")
data<-load("C:/Users/IBM_ADMIN/Desktop/Learning/R/titanic.raw.RData")
library(arules)
rules <- apriori(titanic.raw)
inspect(rules)
rules <- apriori(titanic.raw,
parameter = list(minlen=2, supp=0.005, conf=0.8),
appearance = list(rhs=c("Survived=No", "Survived=Yes"),
default="lhs"),
control = list(verbose=F))
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)
# find redundant rules
subset.matrix <- is.subset(rules.sorted, rules.sorted)
subset.matrix[lower.tri(subset.matrix, diag=T)] <- NA
redundant <- colSums(subset.matrix, na.rm=T) >= 1
which(redundant)
# remove redundant rules
rules.pruned <- rules.sorted[!redundant]
inspect(rules.pruned)
library(arulesViz)
plot(rules)
install.packages("arulesViz")
library(arulesViz)
plot(rules)
plot(rules, method="graph", control=list(type="items"))
plot(rules, method="paracoord", control=list(reorder=TRUE))
View(titanic.raw)
View(titanic.raw)
summary(titanic.raw)
data<-read.csv("C:/Users/IBM_ADMIN/Desktop/Learning/R/data.csv", header = TRUE, sep = ",")
rules <- apriori(data)
inspect(rules)
rules <- apriori(data)
View(data)
View(data)
rules <- apriori(data[,1:1000])
rules <- apriori(data[,c(1:1000)])
subset<- data[,c(1:1000)]
subset<- data[,1:1000]
subset<- data[,100]
subset<- data[c(1:100),]
rules <- apriori(subset)
subset<- data[c(1:1000),]
rules <- apriori(subset)
inspect(rules)
subset<- data[c(1:100),]
rules <- apriori(subset)
inspect(rules)
data<-load("C:/Users/IBM_ADMIN/Desktop/Learning/R/titanic.raw.RData")
rules <- apriori(titanic.raw)
inspect(rules)
rules <- apriori(subset)
inspect(rules)
subset<- data[c(1:50),]
rules <- apriori(subset)
inspect(rules)
require('kernlab')
install.packages("kernlab")
kfunction <- function(linear =0, quadratic=0)
{
k <- function (x,y)
{
linear*sum((x)*(y)) + quadratic*sum((x^2)*(y^2))
}
class(k) <- "kernel"
k
}
n = 25
require('kernlab')
kfunction <- function(linear =0, quadratic=0)
{
k <- function (x,y)
{
linear*sum((x)*(y)) + quadratic*sum((x^2)*(y^2))
}
class(k) <- "kernel"
k
}
n = 25
a1 = rnorm(n)
a2 = 1 - a1 + 2* runif(n)
b1 = rnorm(n)
b2 = -1 - b1 - 2*runif(n)
x = rbind(matrix(cbind(a1,a2),,2),matrix(cbind(b1,b2),,2))
y <- matrix(c(rep(1,n),rep(-1,n)))
svp <- ksvm(x,y,type="C-svc",C = 100, kernel=kfunction(1,0),scaled=c())
plot(c(min(x[,1]), max(x[,1])),c(min(x[,2]), max(x[,2])),type='n',xlab='x1',ylab='x2')
title(main='Linear Separable Features')
ymat <- ymatrix(svp)
points(x[-SVindex(svp),1], x[-SVindex(svp),2], pch = ifelse(ymat[-SVindex(svp)] < 0, 2, 1))
points(x[SVindex(svp),1], x[SVindex(svp),2], pch = ifelse(ymat[SVindex(svp)] < 0, 17, 16))
# Extract w and b from the model
w <- colSums(coef(svp)[[1]] * x[SVindex(svp),])
b <- b(svp)
# Draw the lines
abline(b/w[2],-w[1]/w[2])
abline((b+1)/w[2],-w[1]/w[2],lty=2)
abline((b-1)/w[2],-w[1]/w[2],lty=2)
require('kernlab')
kfunction <- function(linear =0, quadratic=0)
{
k <- function (x,y)
{
linear*sum((x)*(y)) + quadratic*sum((x^2)*(y^2))
}
class(k) <- "kernel"
k
}
n = 20
r = runif(n)
a = 2*pi*runif(n)
a1 = r*sin(a)
a2 = r*cos(a)
r = 2+runif(n)
a = 2*pi*runif(n)
b1 = r*sin(a)
b2 = r*cos(a)
x = rbind(matrix(cbind(a1,a2),,2),matrix(cbind(b1,b2),,2))
y <- matrix(c(rep(1,n),rep(-1,n)))
svp <- ksvm(x,y,type="C-svc",C = 100, kernel=kfunction(0,1),scaled=c())
par(mfrow=c(1,2))
plot(c(min(x[,1]), max(x[,1])),c(min(x[,2]), max(x[,2])),type='n',xlab='x1',ylab='x2')
title(main='Feature Space')
ymat <- ymatrix(svp)
points(x[-SVindex(svp),1], x[-SVindex(svp),2], pch = ifelse(ymat[-SVindex(svp)] < 0, 2, 1))
points(x[SVindex(svp),1], x[SVindex(svp),2], pch = ifelse(ymat[SVindex(svp)] < 0, 17, 16))
# Extract w and b from the model
w2 <- colSums(coef(svp)[[1]] * x[SVindex(svp),]^2)
b <- b(svp)
x1 = seq(min(x[,1]),max(x[,1]),0.01)
x2 = seq(min(x[,2]),max(x[,2]),0.01)
points(-sqrt((b-w2[1]*x2^2)/w2[2]), x2, pch = 16 , cex = .1 )
points(sqrt((b-w2[1]*x2^2)/w2[2]), x2, pch = 16 , cex = .1 )
points(x1, sqrt((b-w2[2]*x1^2)/w2[1]), pch = 16 , cex = .1 )
points(x1,  -sqrt((b-w2[2]*x1^2)/w2[1]), pch = 16, cex = .1 )
points(-sqrt((1+ b-w2[1]*x2^2)/w2[2]) , x2, pch = 16 , cex = .1 )
points( sqrt((1 + b-w2[1]*x2^2)/w2[2]) , x2,  pch = 16 , cex = .1 )
points( x1 , sqrt(( 1 + b -w2[2]*x1^2)/w2[1]), pch = 16 , cex = .1 )
points( x1 , -sqrt(( 1 + b -w2[2]*x1^2)/w2[1]), pch = 16, cex = .1 )
points(-sqrt((-1+ b-w2[1]*x2^2)/w2[2]) , x2, pch = 16 , cex = .1 )
points( sqrt((-1 + b-w2[1]*x2^2)/w2[2]) , x2,  pch = 16 , cex = .1 )
points( x1 , sqrt(( -1 + b -w2[2]*x1^2)/w2[1]), pch = 16 , cex = .1 )
points( x1 , -sqrt(( -1 + b -w2[2]*x1^2)/w2[1]), pch = 16, cex = .1 )
xsq <- x^2
svp <- ksvm(xsq,y,type="C-svc",C = 100, kernel=kfunction(1,0),scaled=c())
plot(c(min(xsq[,1]), max(xsq[,1])),c(min(xsq[,2]), max(xsq[,2])),type='n',xlab='x1^2',ylab='x2^2')
title(main='Quadratic Kernel Space')
ymat <- ymatrix(svp)
points(xsq[-SVindex(svp),1], xsq[-SVindex(svp),2], pch = ifelse(ymat[-SVindex(svp)] < 0, 2, 1))
points(xsq[SVindex(svp),1], xsq[SVindex(svp),2], pch = ifelse(ymat[SVindex(svp)] < 0, 17, 16))
# Extract w and b from the model
w <- colSums(coef(svp)[[1]] * xsq[SVindex(svp),])
b <- b(svp)
# Draw the lines
abline(b/w[2],-w[1]/w[2])
abline((b+1)/w[2],-w[1]/w[2],lty=2)
abline((b-1)/w[2],-w[1]/w[2],lty=2)
library(tm)
## get a sample (10 documents) of the Reuters dataset (comes with package tm)
reut21578 <- system.file("texts", "crude", package = "tm")
#
reuters <- Corpus(DirSource(reut21578),
readerControl = list(reader = readReut21578XML))
### download reuters21578 data first (use first 1000 documents; 1984/85)
file <- "reut2-000.xml"
reuters <- Corpus(ReutersSource(file), readerControl = list(reader = readReut21578XML))
reuters
reuters[[1]]
## Convert to Plain Text Documents
reuters <- tm_map(reuters, as.PlainTextDocument)
reuters[[1]]
## Convert to Lower Case
reuters <- tm_map(reuters, tolower)
reuters[[1]]
## Remove Stopwords
reuters <- tm_map(reuters, removeWords, stopwords("english"))
reuters[[1]]
## Remove Punctuations
reuters <- tm_map(reuters, removePunctuation)
reuters[[1]]
## Stemming
reuters <- tm_map(reuters, stemDocument)
reuters[[1]]
## Remove Numbers
reuters <- tm_map(reuters, removeNumbers)
reuters[[1]]
## Eliminating Extra White Spaces
reuters <- tm_map(reuters, stripWhitespace)
reuters[[1]]
## create a term document matrix
dtm <- DocumentTermMatrix(reuters)
inspect(dtm[1:10, 5001:5010])
findFreqTerms(dtm, 100)
findAssocs(dtm, "washington", .4)
#washington  secretari  political     reagan republican      white      regan
#      1.00       0.49       0.46       0.45       0.45       0.42       0.41
#staff strategist
#0.41       0.41
## do tfxidf
dtm_tfxidf <- weightTfIdf(dtm)
inspect(dtm_tfxidf[1:10, 5001:5010])
## do document clustering
### k-means (this uses euclidean distance)
m <- as.matrix(dtm_tfxidf)
rownames(m) <- 1:nrow(m)
### don't forget to normalize the vectors so Euclidean makes sense
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)
m_norm <- norm_eucl(m)
### cluster into 10 clusters
cl <- kmeans(m_norm, 10)
cl
table(cl$cluster)
### show clusters using the first 2 principal components
plot(prcomp(m_norm)$x, col=cl$cl)
findFreqTerms(dtm[cl$cluster==1], 50)
inspect(reuters[which(cl$cluster==1)])
## hierarchical clustering
library(proxy)
### this is going to take 4-ever (O(n^2))
d <- dist(m, method="cosine")
hc <- hclust(d, method="average")
plot(hc)
cl <- cutree(hc, 50)
table(cl)
findFreqTerms(dtm[cl==1], 50)
data(Titanic)
Titanic
data(Titanic)
Titani
Titanic
dinnames(Titanic)
dimnames(Titanic)
library(MASS)
indep = loglm(˜Class+Sex+Age+Survived, data=Titanic)
indep = loglm(Class+Sex+Age+Survived, data=Titanic)
indep = loglm(~Class+Sex+Age+Survived, data=Titanic)
indep
modelB = loglm(˜Class*Sex*Age*Survived, data=Titanic)
modelB = loglm(~Class*Sex*Age*Survived, data=Titanic)
modelB
coef(modelB)
modelA = loglm(~Class+Sex+Age+Survived, data=Titanic)
coef(modelA)
round(fitted(modelA), 1)
modelB = loglm(~Class+Sex+Age+Survived+Class:Sex+Sex:Survived,data=Titanic)
coef(modelB)
model.aic = step(modelA, scope=list(lower=~., upper=~.ˆ4))
model.aic = step(modelA, scope=list(lower=~., upper=~.^4))
phat.aic = fitted(model.aic)/sum(Titanic)
round(prop.table(phat.aic, c(1,2,3))[,,,"Yes"], 2)
A<-array(0,dim=c(500,1))
x<-rnorm(25,mean=2,sd=1)
for(i in  1:500){
y<-rnorm(25,mean=(3*x+2),sd=1)
beta<-lm(x ~y)
A[i]<-beta$coef[2]
}
Abar<-mean(A)
varA<-var(A)
Abar
varA
summary(A)
setwd("C:/Users/IBM_ADMIN/Documents/GitHub/bicimadmap")
data<-read.csv('data.csv',sep=",",header=TRUE)
require(ggplot2)
require(tabplot)
tableplot(data, cex = 1.8)
View(data)
View(data)
fit <- kmeans(data,6)
fit <- kmeans(data[,c(1,2,4,5)],6)
dataC <- data.frame(dataC, fit$cluster)
dataC <- data.frame(data, fit$cluster)
plotmatrix(data[,c(1,2,4,5,8)],colour=fit$cluster)
fit <- kmeans(data[,c(1,2,4,5)],3)
dataC <- data.frame(data, fit$cluster)
#ScatterPlot
plotmatrix(data[,c(1,2,4,5,8)],colour=fit$cluster)
pairs(data[,c(1,2,4,5,8)],col=fit$cluste,pch=19)
fit <- kmeans(data[,c(1,2,4,5)],4)
dataC <- data.frame(data, fit$cluster)
#ScatterPlot
plotmatrix(data[,c(1,2,4,5,8)],colour=fit$cluster)
pairs(data[,c(1,2,4,5,8)],col=fit$cluste,pch=19)
qplot(bases,bikes, data=data, geom=c("boxplot", "jitter"),
fill=bikes, main="Movies",
xlab="", ylab="Cost per follower")+ opts(axis.text.x=element_text(angle=90, hjust=1))
qplot(bikes,bases, data=data, geom=c("boxplot", "jitter"),
fill=bikes, main="Movies",
xlab="", ylab="Cost per follower")+ opts(axis.text.x=element_text(angle=90, hjust=1))
qplot(bases,bikes, data=data, geom=c("boxplot", "jitter"),
fill=bases, main="Movies",
xlab="", ylab="Cost per follower")+ opts(axis.text.x=element_text(angle=90, hjust=1))
data$bases<-as.factor(data$bases)
qplot(bases,bikes, data=data, geom=c("boxplot", "jitter"),
fill=bases, main="Movies",
xlab="", ylab="Cost per follower")+ opts(axis.text.x=element_text(angle=90, hjust=1))
qplot(bases,free, data=data, geom=c("boxplot", "jitter"),
fill=bases, main="Movies",
xlab="Number of bases", ylab="Free decks")+ opts(axis.text.x=element_text(angle=90, hjust=1))
qplot(free, data=data, geom="density", fill=bases, alpha=I(.5),
main="Distribution of Paritcipation Rate", xlab="Participation Rate",
ylab="Density")
qplot(bikes, data=data, geom="density", fill=bases, alpha=I(.5),
main="Distribution of Free decks per Station type", xlab="Participation Rate",
ylab="Density")
setwd("C:/Users/IBM_ADMIN/Documents/GitHub/bicimadmap/batch")
data<-read.csv('data.csv',sep=",",header=TRUE)
require(ggplot2)
require(tabplot)
#Summary
tableplot(data, cex = 1.8)
View(data)
View(data)
qplot(zone,bikes, data=data, geom=c("boxplot", "jitter"),
fill=zone, main="Free Bikes per Zone",
xlab="Number of bases", ylab="Bikes in deck")+ opts(axis.text.x=element_text(angle=90, hjust=1))
qplot(zone,free, data=data, geom=c("boxplot", "jitter"),
fill=zone, main="Free decks per Zone",
xlab="Number of bases", ylab="Free decks")+ opts(axis.text.x=element_text(angle=90, hjust=1))
qplot(free, data=data, geom="density", fill=zone, alpha=I(.5),
main="Distribution of Free bikes per Zone", xlab="Participation Rate",
ylab="Density")
qplot(bikes, data=data, geom="density", fill=zone, alpha=I(.5),
main="Distribution of Free decks per Zone", xlab="Free Bikes",
ylab="Density")
plotmatrix(data[,c(1,2,5,6,9)],colour=fit$base)
plotmatrix(data[,c(1,2,5,6,9)],colour=data$base)
plotmatrix(data[,c(1,2,5,6,9)],colour=data$base)
plotmatrix(data[,c(1,2,5,6,9)],colour=data$zone)
plotmatrix(data[,c(1,2,5,6,9,12,13)],colour=data$base)
pairs(data[,c(1,2,5,6,9,12,13)],colour=data$base,pch=19)
pairs(data[,c(1,2,5,6,9,12,13)],col=data$base,pch=19)
pairs(data[,c(1,2,5,6,9,12,13)],col=data$zone,pch=19)
pairs(data[,c(1,2,5,6,9,12,13)],col=fit$cluster,pch=19)
pairs(data[,c(1,2,5,6,9,12,13)],col=fit$cluster,pch=19)
